""" Helper script to analyze Hi-C data to study changes in genome conformation during repair of Cas9 breaks """
__author__ = "Alberto Marin"
__license__ = "MIT"
__version__ = "0.9"
__maintainer__ = "Alberto Marin"
####################################### IMPORT FUNCTIONS #######################################
import subprocess as sp
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import os
import numpy as np
import re
from . import newchip as nc
import random
import csv

CHR = ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11',
       'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21',
       'chr22', 'chrX', 'chrY']

def load_nparray(array):
    """ Load dataset as numpy array. """
    return np.loadtxt(array, dtype=object, delimiter=',')

def get_genome_dict(genome_str):
    """ Return dict that holds the number of base pairs for each chromosome in 'hg38','hg19','mm10'.

    :param genome_str: 'hg38', 'hg19', or 'mm10'
    :return: dict with keys as chromosomes, values as maximum coordinate of each chromosome key
    """
    d = {}
    dirname, filename = os.path.split(os.path.abspath(__file__))
    with open(os.path.dirname(dirname) + "/lib/%s.sizes" % genome_str, 'r') as f:
        for row in csv.reader(f, delimiter='\t'):
            d[row[0]] = int(row[1])
    return d

def read_tgts_peaks(file_peaks, genome, res, width, max_cter=None, mrg_tgts = 0, sort=1, cut_bin=1):
    """ Function that reads a peaks file (MRE, BLISS, etc) and returns a list containing the chromosome, average position
        of the cut and a genomic interval of a given window that contains the cut site. The extremes of the interval
        are integers of the "res" parameter, in order to be able to retrieve a HiC matrix in the downstream analysis.
        :param file_peaks: CSV file generated by MACS2 that contains the sites with highest BLISS/MRE11 signal. The lines should
            be ordered according to enrichment (highest to lowest).
        :param genome: [genome name, path to genome with .fa extension], i.e. ['hg38', path/to/hg38.fa]
        :param res: resolution of the HiC matrix for downstream analysis.
        :param width: radius of window from peak center for output interval
        :param max_cter: number of targets to consider
        :param mrg_tgts: whether to merge targets that are close to one another (default: 0 [don't merge])
        :param sort: whether to sort output by chromosome and location (default: 1 [sort])
        :param cut_bin: whether to consider a bin for the cut site or not (default: 1 [take bin at cut site])
        :return: outlist with [(chr_i, aver_i, span_sta, span_end, fenr_i)] """
    file = load_nparray(file_peaks)
    g_dict = get_genome_dict(genome[0])
    outlist = []
    cter = 0
    for i in range(1, file.shape[0]):
        unqnss = 1
        row = file[i, :]
        chr_i = row[0]
        fenr_i = row[7]
        if chr_i not in CHR:
            continue
        if cut_bin == 1:
            aver_i = (round((int(row[1]) + int(row[2])) / 2 / res)) * res
            span_sta = aver_i - width
        else:
            aver_i = (int((int(row[1]) + int(row[2])) / 2 / res)) * res
            span_sta = aver_i - width + res
        span_end = aver_i + width
        if ((max(1, span_sta) == 1) or (min(g_dict[chr_i], span_end) == g_dict[chr_i])):
            continue # Discard breaks that are too close to the end of the chromosome.
        if mrg_tgts == 1: # check if current target is too close to a previous one. If it is, do not add to the list.
            for j in range(len(outlist)):
                if ((outlist[j][0] == chr_i) and (abs(aver_i-outlist[j][1]) < res)):
                    unqnss = 0
                    continue
        cter += 1
        if max_cter is not None:
            if cter > max_cter:
                break
        if unqnss == 1:
            outlist.append([chr_i, aver_i, span_sta, span_end, fenr_i])
    if sort == 1:
        outlist = sorted(outlist, key=lambda x: (x[1]))
        outlist = sorted(outlist, key=lambda x: (x[0][3:]))
    return outlist

def cut_centered_4c(tgts_list, jcr_path, data_path, hicfile_neg, hicfile_ep, res, width, fileout, vp_bins, obs = 'oe', norm = 'KR', cut_bin=1):
    """
    Compute 4C-like profiles of log2(Cas9/NoEP) using cut sites as viewpoints. Two profiles are computed and saved as csv files:
    one, using the left of the cut site, and a second one using the right.
    :param tgts_list: input list of targets, obtained from read_targets_for_hic or similar
    :param jcr_path: path to juicer folder
    :param data_path: path to output folder
    :param hicfile_neg: path to Hi-C file, NoEP
    :param hicfile_ep: path to Hi-C file, AluGG EP
    :param res: resolution to retrieve Hi-C matrices
    :param width: width to look for enriched contacts between cut site and neighboring chromatin
    :param fileout: output files (_left.csv and _right.csv)
    :param vp_bins: number of Hi-C bins around cut site to use as viewpoint
    :param obs: for juicer-dump, observed, or observed over expected (oe) (default: oe).
    :param norm: normalization approach used by juicer (default: KR).
    :param cut_bin: whether to include the cut site as a bin or not (default: 1).
    :return:
    """
    num_bins = int(width / res) * 2 + 1 if cut_bin == 1 else int(width / res) * 2
    file_prov_neg, file_prov_ep = data_path + "out_prov_mat_neg.txt", data_path + "out_prov_mat_ep.txt"
    [vp_end_lft, vp_str_rgt] = [int(num_bins/2)-1, int(num_bins/2)+1] if cut_bin == 1 else [int(num_bins/2) - 1, int(num_bins/2)]
    vp_str_lft = vp_end_lft - vp_bins
    vp_end_rgt = vp_str_rgt + vp_bins
    outlist_left, outlist_right = [], []
    aver_list_lft, aver_list_rgt = [], []
    cter = 0
    for i in tgts_list:
        wlist_lft, wlist_rgt = [0.0] * num_bins, [0.0] * num_bins
        chr_i, cut_i, span0_i, span1_i = i[0][3:], i[1], i[2], i[3]
        rng_i = chr_i + ":" + str(span0_i) + ":" + str(span1_i)
        sp.run(['java', '-jar', jcr_path, 'dump', obs, norm, hicfile_neg, rng_i, rng_i, 'BP', str(res),
                file_prov_neg])
        sp.run(['java', '-jar', jcr_path, 'dump', obs, norm, hicfile_ep, rng_i, rng_i, 'BP', str(res),
                file_prov_ep])
        mat_neg = read_HiC_matrix(file_prov_neg, num_bins, span0_i, span0_i, res)
        mat_ep = read_HiC_matrix(file_prov_ep, num_bins, span0_i, span0_i, res)
        for j in range(num_bins):
            cnt_lft, cnt_rgt = 0.0, 0.0
            for k in range(vp_str_lft, vp_end_lft):
                if mat_ep[j, k] * mat_neg[j, k] != 0:
                    cnt_lft += np.log2(mat_ep[j, k] / mat_neg[j, k])
            for k in range(vp_str_rgt, vp_end_rgt):
                if mat_ep[j, k] * mat_neg[j, k] != 0:
                    cnt_rgt += np.log2(mat_ep[j, k] / mat_neg[j, k])
            wlist_lft[j], wlist_rgt[j] = cnt_lft, cnt_rgt
        outlist_left.append([chr_i, cut_i] + wlist_lft)
        outlist_right.append([chr_i, cut_i] + wlist_rgt)
        sp.run(['rm', file_prov_neg, file_prov_ep])
        cter = cter + 1
    for col in range(num_bins):
        aver_i_lft, aver_i_rgt = 0, 0
        for line in range(len(tgts_list)):
            aver_i_lft += float(outlist_left[line][col + 2])
            aver_i_rgt += float(outlist_right[line][col + 2])
        aver_i_lft, aver_i_rgt = aver_i_lft / int(len(tgts_list)), aver_i_rgt / int(len(tgts_list))
        aver_list_lft.append(aver_i_lft)
        aver_list_rgt.append(aver_i_rgt)
    outlist_left.append(["Average", "NA"] + aver_list_lft)
    outlist_right.append(["Average", "NA"] + aver_list_rgt)
    if cut_bin==1:
        head = ",".join(["chr", "cut"] + list(map(str, range(-width, width + res, res))))
    else:
        head = ",".join(["chr", "cut"] + list(map(str, range(-width+int(res/2), width + int(res/2), res))))
    np.savetxt(fileout + "_left_4c.csv", np.asarray(outlist_left), fmt='%s', delimiter=',', header=head)
    np.savetxt(fileout + "_right_4c.csv", np.asarray(outlist_right), fmt='%s', delimiter=',', header=head)
    return [outlist_left, outlist_right]

def read_HiC_matrix(matfile, nbins, bin0, bin1, resol):
    """ Function that reads a .hic file and saves it into a numpy matrix.
    :param matfile: input .hic file.
    :param nbins: number of bins in the .hic file/numpy matrix.
    :param bin0: start coordinate where hic matrix was dumped.
    :param resol: resolution at which the hic matrix was dumped.
    :return: mtrx_np, numpy hic matrix of the .hic file.
    """
    matrix = np.zeros(shape=(nbins, nbins))
    f = open(matfile, 'r')
    lines = f.readlines()
    for line in lines:
        if line.split('\t')[2] == "NaN\n":
            continue
        coo0 = int((int(line.split('\t')[0])-bin0)/resol)
        coo1 = int((int(line.split('\t')[1])-bin1)/resol)
        matrix[coo0, coo1] = float(line.split('\t')[2][:-3]) if line.split('\t')[2][-2:] == "\n" else float(line.split('\t')[2])
    for i in range(0, nbins):
        for j in range(i, nbins):
            matrix[j, i] = matrix[i, j]
    return matrix

def get_mean_HiC_ratio(tgts_list, jcr_path, data_path, hicfile_neg, hicfile_ep, res, width, obs = 'oe', norm = 'KR', cut_bin = 1):
    """ Function that outputs the average (across a list of target sites) of the log2 of the ratio of two Hi-C matrices.
    :param tgts_list: list of target sites, of the form [(chr_i, aver_i, span_sta, span_end, f_enr)].
    :param jcr_path: path to juicer software
    :param data_path: path to folder where provisional hic matrices will be generated.
    :param hicfile_neg: path to negative (denominator) .hic to be analyzed.
    :param hicfile_pos: path to positive (numerator) .hic to be analyzed.
    :param res: resolution of the hic matrices that will be dumped.
    :param width: width of the hic matrix that will de dumped.
    :param obs: observed or oe, for dumping hic matrices. default: oe.
    :param norm: normalization choice for hic matrices. default: KR.
    :param cut_bin: whether to consider a bin for the cut site or not (default: 1 [take bin at cut site])
    :return: mtrx_np, numpy hic matrix, averaged around the input sites.
    """
    num_bins = int(width / res) * 2 + 1 if cut_bin==1 else int(width / res) * 2
    file_prov_neg, file_prov_ep = data_path + "out_prov_mat_neg.txt", data_path + "out_prov_mat_ep.txt"
    mtrx_rat = np.zeros(shape=(num_bins, num_bins))
    cter = 0
    for i in tgts_list:
        chr_i = i[0][3:]
        span0_i = i[2]
        span1_i = i[3]
        rng_i = chr_i + ":" + str(span0_i) + ":" + str(span1_i)
        sp.run(['java', '-jar', jcr_path, 'dump', obs, norm, hicfile_neg, rng_i, rng_i, 'BP', str(res),
                file_prov_neg])
        sp.run(['java', '-jar', jcr_path, 'dump', obs, norm, hicfile_ep, rng_i, rng_i, 'BP', str(res),
                file_prov_ep])
        mat_neg = read_HiC_matrix(file_prov_neg, num_bins, span0_i, span0_i, res)
        mat_ep = read_HiC_matrix(file_prov_ep, num_bins, span0_i, span0_i, res)
        for j in range(num_bins):
            for k in range(j, num_bins):
                if mat_ep[j, k]*mat_neg[j, k] != 0:
                    log_dsb = np.log2(mat_ep[j, k]/mat_neg[j, k])
                    mtrx_rat[j, k] += log_dsb
        sp.run(['rm', file_prov_neg, file_prov_ep])
        cter = cter + 1
        print(cter)
    for i in range(num_bins):
        for j in range(i, num_bins):
            mtrx_rat[j, i] = mtrx_rat[i, j]
    return mtrx_rat/cter

def plot_LE_matrix(inmatrix, outfile, possample, negsample, width, zscale=0.25, extn = "png", zmin=0):
    """ Function that plots the loop-extrusion matrix, i.e. the log enrichment of contacts averaged around cut sites.
    :param inmatrix: input numpy hic matrix to plot.
    :param outfile: output file for the plot.
    :param possample: name of the positive sample (with DSBs).
    :param negsample: name of the negative sample (without DSBs).
    :param width: width of the plot, in bps.
    :param extn: extension of the output file. default: png.
    """
    outname = outfile + "." + extn
    if negsample == "NA":
        titleplot = "Contacts count. " + possample
        plt.imshow(inmatrix, vmin=zmin, vmax=zscale, extent=[-width, width, width, -width], interpolation='nearest')
    else:
        titleplot = "log2(+DSB/-DSB). " + possample + "/" + negsample
        plt.imshow(inmatrix, vmin=-zscale, vmax=zscale, extent=[-width, width, width, -width])
    plt.xlabel('Distance from cut site (Mb)', fontsize=14)
    plt.ylabel('Distance from cut site (Mb)', fontsize=14)
    plt.xticks(fontsize=14)
    plt.yticks(fontsize=14)
    plt.title(titleplot, fontsize=14)
    ctax = plt.axes([0.85, 0.1, 0.03, 0.5])
    plt.colorbar(cax=ctax)
    plt.savefig(outname, format=extn)
    plt.close()

def per_site_is(generator, isfile, outfile, span=1):
    """
    Funcion that calculates the insulation score per site.
    :param generator: generator with Cas9 on-target sites
    :param isfile: insulation score file computed using cworld
    :param outfile: output csv file, where each line is chr, cut_site, Ins-Score Raw, Smooth, Regular.
    :param span: span window (in number of is-file bins) to compute insulation score around cut site
    """
    is_vals = np.loadtxt(isfile, dtype=object, delimiter='\t')
    numlines = is_vals.shape[0]
    out_list = []
    for rs, cut, sen, pam, gui, mis, guide in generator:
        iscore_raw, iscore_smooth, iscore = 0.0, 0.0, 0.0
        chr_i = re.split('[:-]', rs)[0]
        for j in range(1, numlines):
            chr_j = is_vals[j][0]
            if chr_i != chr_j:
                continue
            if int(is_vals[j][1]) < cut < int(is_vals[j][2]):
                for win_i in range(-span, span+1):
                    iscore_raw += float(is_vals[j + win_i][3])
                    iscore_smooth += float(is_vals[j + win_i][4])
                    iscore += float(is_vals[j + win_i][5])
                out_list.append([chr_i, cut] + [iscore_raw, iscore_smooth, iscore])
                continue
    head = ",".join(["chr", "cut", "Ins-Score Raw", "Ins-Score Smooth", "Ins-Score"])
    np.savetxt(outfile + "_per-site_is.csv", np.asarray(out_list), fmt='%s', delimiter=',', header=head)

def per_site_is_peaks(list_tgts, isfile, outfile, span=1):
    """
    Same as per_site_is above but using BLISS/MRE11 macs2 peaks as input.
    :param generator: generator with Cas9 on-target sites
    :param isfile: insulation score file
    :param outfile: output csv file, where each line is chr, cut_site, Ins-Score Raw, Smooth, Regular.
    :param span: span window (in number of is-file bins) to compute insulation score around cut site
    :return:
    """
    is_vals = np.loadtxt(isfile, dtype=object, delimiter='\t')
    numlines = is_vals.shape[0]
    out_list = []
    for chr_i, aver_i, span_sta, span_end, fenr_i in list_tgts:
        iscore_raw, iscore_smooth, iscore = 0.0, 0.0, 0.0
        for j in range(1, numlines):
            chr_j = is_vals[j][0]
            if chr_i != chr_j:
                continue
            if int(is_vals[j][1]) < aver_i < int(is_vals[j][2]):
                for win_i in range(-span, span+1):
                    iscore_raw += float(is_vals[j + win_i][3])
                    iscore_smooth += float(is_vals[j + win_i][4])
                    iscore += float(is_vals[j+win_i][5])
                out_list.append([chr_i, aver_i] + [iscore_raw, iscore_smooth, iscore])
                continue
    head = ",".join(["chr", "cut", "Ins Score Raw", "Ins Score Smooth", "Insulation Score"])
    np.savetxt(outfile + "_bliss_sites_per-site_is.csv", np.asarray(out_list), fmt='%s', delimiter=',', header=head)

def is_profiles(generator, isfile, outfile, res = 25, span=20):
    """
    Funcion that calculates the change in insulation score after DNA damage per site
    :param generator: generator
    :param isfile: insulation score file
    :param span: span window (in number of is-file bins) to compute insulation score around cut site
    :param outfile: output csv file, where each line is chr, cut_site, NoEP-IS, EP-IS, Difference-IS
    :return:
    """
    is_vals = np.loadtxt(isfile, dtype=object, delimiter='\t')
    numlines = is_vals.shape[0]
    peaks_raw, peaks_smooth, peaks_is = [], [], []
    numrows = 2 * span + 1
    for rs, cut, sen, pam, gui, mis, guide in generator:
        chr_i = re.split('[:-]', rs)[0]
        for j in range(1, numlines):
            chr_j = is_vals[j][0]
            if chr_i != chr_j:
                continue
            if int(is_vals[j][1]) < cut < int(is_vals[j][2]):
                if j-span < 1 or j+span > numlines:
                    print("Site too close to end of file")
                    continue
                elif ((is_vals[j-span][0] != chr_j) or (is_vals[j+span][0] != chr_j)):
                    print("Site too close to end of chromosome")
                    continue
                else:
                    wlist_raw, wlist_smooth, wlist_is = [0] * numrows, [0] * numrows, [0] * numrows
                    for row_i in range(numrows):
                        site = j - span + row_i
                        wlist_raw[row_i] = float(is_vals[site][3])
                        wlist_smooth[row_i] = float(is_vals[site][4])
                        wlist_is[row_i] = float(is_vals[site][5])
                    peaks_raw.append([chr_i, cut] + wlist_raw)
                    peaks_smooth.append([chr_i, cut] + wlist_smooth)
                    peaks_is.append([chr_i, cut] + wlist_is)
                continue
    head = ",".join(["chr", "cut"] +
                    list(map(str, range(-span*res, (span + 1) *res, res))))
    aver_list = []
    if wlist_is is not None:
        for col in range(len(wlist_is)):
            aver_i = 0
            for line in range(len(peaks_is)):
                aver_i += float(peaks_is[line][col + 2])
            aver_i = aver_i / int(len(peaks_is))
            aver_list.append(aver_i)
    peaks_is.append(["Average", "NA"] + aver_list)
    np.savetxt(outfile + "_is_profile.csv", np.asarray(peaks_is), fmt='%s', delimiter=',', header=head)

def gen_TAD_bounds_around_cuts(tadfile, file_bliss, genome, max_cter, width, min_dist, win, check_prox=True):
    """
    Outputs TAD boundaries that are within a given distance from the cut sites, given by bliss peaks file
    :param tadfile: file with TAD annotations
    :param file_bliss: BLISS peaks file, output of MACS2
    :param genome: [genome name, path to genome with .fa extension], i.e. ['hg38', path/to/hg38.fa]
    :param max_cter: number of DSBs to consider for the analysis (number of BLISS peaks to read)
    :param width: window around the cut sites to look for TAD boundaries
    :param min_dist: minimum distance from break for a TAD boundary to be included
    :param win: genomic window for downstream analysis
    :param check_prox: discard TAD boundaries that are too close to a different cut site (default: True)
    :yield: list of TAD boundaries proximal to cut sites.
    """
    tad_bounds = np.loadtxt(tadfile, dtype=object, delimiter='\t')
    outlist = []
    num_tads = tad_bounds.shape[0]
    peaks = load_nparray(file_bliss)
    num_tgts = min(peaks.shape[0], max_cter + 1) if max_cter is not None else peaks.shape[0]
    peaks = np.array(sorted(peaks[1:num_tgts, :], key=lambda x: (int(x[1]))))
    peaks = np.array(sorted(peaks, key=lambda x: (x[0])))
    hgsize = nc.get_genome_dict(genome[0])
    for i in range(num_tgts-1):
        row = peaks[i, :]
        chr_i = row[0]
        if chr_i not in CHR:
            continue
        cut_i = int(row[4])
        for j in range(1, num_tads):
            tad_close=0
            chr_j = tad_bounds[j][0]
            if chr_j != chr_i:
                continue
            pos_j = int(tad_bounds[j][1])
            if ((cut_i-width < pos_j < cut_i+width) and abs(cut_i-pos_j) > min_dist):
                span_sta = pos_j - win
                span_end = pos_j + win
                if ((span_sta < 0) or (span_end > hgsize[chr_j])):
                    continue
                span_rs = "%s:%i-%i" % (chr_j, span_sta, span_end)
                sen_j = "+" if cut_i < pos_j else "-"
                if check_prox == True:
                    for k in range(max(1, i-1), min(i+1, num_tgts)): # Discard TAD boundaries that are too close to a neighboring cut.
                        row_k = peaks[k, :]
                        chr_k = row_k[0]
                        cut_k = int(row_k[4])
                        if ((chr_j == chr_k) and (span_sta < cut_k < span_end)):
                            print("TAD boundary will be discarded: too close to another cut site")
                            tad_close=1
                            break
                    if tad_close==0:
                        outlist.append([chr_j, span_rs, pos_j, sen_j, "NA", "NA", "NA", "NA"])
                else:
                    outlist.append([chr_j, span_rs, pos_j, sen_j, "NA", "NA", "NA", "NA"])
    outlist = sorted(outlist, key=lambda x: (x[2]))
    outlist = sorted(outlist, key=lambda x: (x[0]))
    for out in outlist:
        yield tuple(out[1:])

def gen_rands_around_cuts(file_bliss, genome, max_cter, sites_per_cut, width, min_dist, win, seed=1, check_prox = True):
    """
    Outputs random sites that are within a given distance from the cut sites, given by bliss peaks file
    :param file_bliss: BLISS peaks file, output of MACS2
    :param genome: [genome name, path to genome with .fa extension], i.e. ['hg38', path/to/hg38.fa]
    :param max_cter: number of DSBs to consider for the analysis (number of BLISS peaks to read)
    :param sites_per_cut: number of random sites to produce per DSB
    :param width: window around the cut sites to look for TAD boundaries
    :param min_dist: minimum distance from break for a TAD boundary to be included
    :param win: genomic window for downstream analysis
    :param seed: seed to use for random number generator
    :param check_prox: discard TAD boundaries that are too close to a different cut site (default: True)
    :yield: list of random sites proximal to cut sites.
    """
    outlist = []
    peaks = load_nparray(file_bliss)
    num_tgts = min(peaks.shape[0], max_cter + 1) if max_cter is not None else peaks.shape[0]
    peaks = np.array(sorted(peaks[1:num_tgts, :], key=lambda x: (int(x[1]))))
    peaks = np.array(sorted(peaks, key=lambda x: (x[0])))
    hgsize = nc.get_genome_dict(genome[0])
    if seed is not None:
        random.seed(seed)
    for i in range(num_tgts-1):
        tad_close=0
        row = peaks[i, :]
        chr_i = row[0]
        if chr_i not in CHR:
            continue
        cut_i = int(row[4])
        for j in range(sites_per_cut):
            sign = (random.randint(0,1)-0.5)*2
            dist = random.randint(min_dist, width)
            pos_j = cut_i + int(sign) * dist
            span_sta = pos_j - win
            span_end = pos_j + win
            if ((span_sta < 0) or (span_end > hgsize[chr_i])):
                continue
            span_rs = "%s:%i-%i" % (chr_i, span_sta, span_end)
            sen_j = "+" if cut_i < pos_j else "-"
            if check_prox == True:
                for k in range(max(1, i - 1), min(i + 1, num_tgts)):  # Discard random sites that are too close to a neighboring cut.
                    row_k = peaks[k, :]
                    chr_k = row_k[0]
                    cut_k = int(row_k[4])
                    if ((chr_i == chr_k) and (span_sta < cut_k < span_end)):
                        print("Site will be discarded: too close to another cut site")
                        tad_close = 1
                        break
                if tad_close == 0:
                    outlist.append([chr_i, span_rs, pos_j, sen_j, "NA", "NA", "NA", "NA"])
            else:
                outlist.append([chr_i, span_rs, pos_j, sen_j, "NA", "NA", "NA", "NA"])
    outlist = sorted(outlist, key=lambda x: (x[2]))
    outlist = sorted(outlist, key=lambda x: (x[0]))
    for out in outlist:
        yield tuple(out[1:])